#!/usr/bin/env python3
"""
åŠ¨æ€åˆ†é…æœªå¼€å§‹çš„Jobs
æ‰«ææ‰€æœ‰ä»»åŠ¡ï¼Œæ‰¾å‡º annotated_frames == 0 çš„ jobsï¼Œé‡æ–°åˆ†é…ç»™æŒ‡å®šäººå‘˜
"""
import requests
import json
import logging
from pathlib import Path
from datetime import datetime
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed

# é…ç½®æ—¥å¿—
log_dir = Path('logs')
log_dir.mkdir(exist_ok=True)
log_file = log_dir / f'reassign_jobs_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler(log_file, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# æ’é™¤çš„ä»»åŠ¡ï¼ˆæ—§å¹³å°ï¼‰
EXCLUDED_TASKS = {1967925}


class CVATClient:
    """CVATå®¢æˆ·ç«¯"""
    
    def __init__(self, base_url, api_key):
        self.base_url = base_url.rstrip('/')
        self.api_key = api_key
        self.headers = {'Authorization': f'Token {api_key}'}
    
    def get_all_tasks(self, organization_slug=None):
        """è·å–æ‰€æœ‰ä»»åŠ¡"""
        url = f'{self.base_url}/api/tasks'
        params = {'page_size': 500}
        if organization_slug:
            params['org'] = organization_slug
        
        all_tasks = []
        page = 1
        
        while True:
            params['page'] = page
            response = requests.get(url, headers=self.headers, params=params, timeout=30)
            response.raise_for_status()
            data = response.json()
            
            results = data.get('results', [])
            all_tasks.extend(results)
            
            if not data.get('next'):
                break
            page += 1
        
        return all_tasks
    
    def get_task_jobs(self, task_id):
        """è·å–ä»»åŠ¡çš„æ‰€æœ‰jobs"""
        url = f'{self.base_url}/api/jobs'
        params = {'task_id': task_id, 'page_size': 1000}
        
        response = requests.get(url, headers=self.headers, params=params, timeout=30)
        response.raise_for_status()
        return response.json().get('results', [])
    
    def get_job_annotations_count(self, job_id):
        """è·å–jobçš„å·²æ ‡æ³¨å¸§æ•°"""
        url = f'{self.base_url}/api/jobs/{job_id}/annotations'
        
        try:
            response = requests.get(url, headers=self.headers, timeout=30)
            response.raise_for_status()
            data = response.json()
            
            annotated_frames = set()
            for shape in data.get('shapes', []):
                annotated_frames.add(shape.get('frame'))
            for track in data.get('tracks', []):
                for shape in track.get('shapes', []):
                    annotated_frames.add(shape.get('frame'))
            
            return len(annotated_frames)
        except:
            return -1  # å‡ºé”™è¿”å›-1ï¼Œè¡¨ç¤ºæ— æ³•ç¡®å®š
    
    def assign_job(self, job_id, assignee_id):
        """åˆ†é…jobç»™æ ‡æ³¨äººå‘˜"""
        url = f'{self.base_url}/api/jobs/{job_id}'
        payload = {'assignee': assignee_id}
        headers = {**self.headers, 'Content-Type': 'application/json'}
        
        response = requests.patch(url, headers=headers, json=payload, timeout=30)
        response.raise_for_status()
        return True
    
    def get_organization_members(self, organization_slug):
        """è·å–ç»„ç»‡æ‰€æœ‰æˆå‘˜ï¼ˆåŒ…æ‹¬ç®¡ç†å‘˜ï¼‰"""
        url = f'{self.base_url}/api/memberships'
        params = {'org': organization_slug, 'page_size': 100}
        
        response = requests.get(url, headers=self.headers, params=params, timeout=30)
        response.raise_for_status()
        data = response.json()
        
        members = []
        for member in data.get('results', []):
            user = member.get('user', {})
            role = member.get('role', 'worker')
            
            user_id = user.get('id')
            username = user.get('username')
            first_name = user.get('first_name', '')
            last_name = user.get('last_name', '')
            
            if first_name or last_name:
                display_name = f"{first_name} {last_name}".strip()
            else:
                display_name = username
            
            members.append({
                'id': user_id,
                'name': display_name,
                'username': username,
                'role': role
            })
        
        return members



def reassign_jobs(config_file='config.json', task_ids=None):
    """åŠ¨æ€åˆ†é…æœªå¼€å§‹çš„jobs"""
    logger.info("="*60)
    logger.info("åŠ¨æ€åˆ†é…æœªå¼€å§‹çš„Jobs")
    logger.info("="*60)
    
    # 1. åŠ è½½é…ç½®
    logger.info("\nğŸ“– åŠ è½½é…ç½®æ–‡ä»¶...")
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
    except FileNotFoundError:
        logger.error(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        return
    
    cvat_url = config['cvat']['url']
    api_key = config['cvat']['api_key']
    organization_slug = config.get('organization', {}).get('slug')
    
    client = CVATClient(cvat_url, api_key)
    
    # 2. å®æ—¶è·å–ç»„ç»‡æ‰€æœ‰æˆå‘˜ï¼ˆåŒ…æ‹¬ç®¡ç†å‘˜ï¼‰
    logger.info("\nğŸ‘¥ è·å–ç»„ç»‡æˆå‘˜...")
    all_members = client.get_organization_members(organization_slug)
    if not all_members:
        logger.error("âŒ æœªæ‰¾åˆ°ç»„ç»‡æˆå‘˜")
        return
    logger.info(f"âœ… æ‰¾åˆ° {len(all_members)} ä¸ªæˆå‘˜")
    
    # 3. è·å–ä»»åŠ¡åˆ—è¡¨
    logger.info("\nğŸ“‹ è·å–ä»»åŠ¡åˆ—è¡¨...")
    
    if task_ids:
        # ä½¿ç”¨æŒ‡å®šçš„ä»»åŠ¡ID
        tasks = []
        for task_id in task_ids:
            url = f'{cvat_url}/api/tasks/{task_id}'
            try:
                response = requests.get(url, headers=client.headers, timeout=30)
                response.raise_for_status()
                tasks.append(response.json())
            except Exception as e:
                logger.error(f"âŒ è·å–ä»»åŠ¡å¤±è´¥: task_id={task_id}, {e}")
    else:
        tasks = client.get_all_tasks(organization_slug)
    
    tasks = [t for t in tasks if t['id'] not in EXCLUDED_TASKS]
    logger.info(f"âœ… æ‰¾åˆ° {len(tasks)} ä¸ªä»»åŠ¡")
    
    # 4. æ‰«æjobsï¼Œç»Ÿè®¡æ¯ä¸ªäººçš„å·¥ä½œé‡
    logger.info("\nğŸ” æ‰«æJobsçŠ¶æ€...")
    unstarted_jobs = []
    user_started_jobs = defaultdict(int)  # æ¯ä¸ªäººå·²å¼€å§‹çš„jobsæ•°é‡ï¼ˆä¸èƒ½åŠ¨çš„ï¼‰
    
    for task in tasks:
        task_id = task['id']
        task_name = task['name']
        
        jobs = client.get_task_jobs(task_id)
        if not jobs:
            continue
        
        logger.info(f"   ä»»åŠ¡: {task_name} (ID: {task_id}) - {len(jobs)} jobs")
        
        # å¹¶å‘æ£€æŸ¥æ¯ä¸ªjob
        def check_job(job):
            job_id = job['id']
            annotated = client.get_job_annotations_count(job_id)
            return job, annotated
        
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = [executor.submit(check_job, job) for job in jobs]
            for future in as_completed(futures):
                job, annotated = future.result()
                assignee = job.get('assignee')
                assignee_id = assignee.get('id') if assignee else None
                
                if annotated == 0:
                    # æœªå¼€å§‹çš„jobï¼Œå¯ä»¥é‡æ–°åˆ†é…
                    unstarted_jobs.append({
                        'job_id': job['id'],
                        'task_id': task_id,
                        'task_name': task_name,
                        'start_frame': job.get('start_frame', 0),
                        'stop_frame': job.get('stop_frame', 0),
                        'current_assignee': assignee.get('username') if assignee else None,
                        'current_assignee_id': assignee_id
                    })
                else:
                    # å·²å¼€å§‹çš„jobï¼Œç»Ÿè®¡åˆ°å¯¹åº”äººå‘˜
                    if assignee_id:
                        user_started_jobs[assignee_id] += 1
    
    if not unstarted_jobs:
        logger.info("\nâœ… æ²¡æœ‰æœªå¼€å§‹çš„Jobséœ€è¦åˆ†é…")
        return
    
    logger.info(f"\nğŸ“Š æ‰¾åˆ° {len(unstarted_jobs)} ä¸ªæœªå¼€å§‹çš„Jobs")
    
    # 5. æ˜¾ç¤ºæœªå¼€å§‹çš„jobs
    logger.info("\næœªå¼€å§‹çš„Jobsåˆ—è¡¨:")
    for idx, job in enumerate(unstarted_jobs):
        frame_count = job['stop_frame'] - job['start_frame'] + 1
        current = job['current_assignee'] or 'æœªåˆ†é…'
        logger.info(f"   {idx+1}. Job {job['job_id']} ({frame_count}å¸§) - å½“å‰: {current}")
    
    # 6. æ˜¾ç¤ºæ‰€æœ‰æˆå‘˜ï¼Œè®©ç”¨æˆ·é€‰æ‹©å‚ä¸åˆ†é…çš„äºº
    print("\n" + "="*50)
    print("ğŸ“‹ ç»„ç»‡æˆå‘˜åˆ—è¡¨ï¼ˆå®æ—¶è·å–ï¼‰:")
    print("="*50)
    for idx, m in enumerate(all_members):
        role_tag = f"[{m['role']}]" if m['role'] in ['owner', 'maintainer'] else ""
        print(f"   {idx+1}. {m['name']} (@{m['username']}) {role_tag}")
    
    # è®©ç”¨æˆ·é€‰æ‹©å‚ä¸åˆ†é…çš„äººå‘˜
    print(f"\nè¯·è¾“å…¥è¦å‚ä¸åˆ†é…çš„äººå‘˜ç¼–å·ï¼ˆç”¨ç©ºæ ¼åˆ†éš”ï¼Œå¦‚: 1 2 3ï¼‰")
    print(f"æˆ–è¾“å…¥ 'all' é€‰æ‹©å…¨éƒ¨: ", end='')
    selection = input().strip()
    
    if selection.lower() == 'all':
        selected_assignees = all_members[:]
    else:
        try:
            indices = [int(x) - 1 for x in selection.split()]
            selected_assignees = [all_members[i] for i in indices if 0 <= i < len(all_members)]
            if not selected_assignees:
                logger.error("âŒ æœªé€‰æ‹©ä»»ä½•äººå‘˜")
                return
        except (ValueError, IndexError):
            logger.error("âŒ æ— æ•ˆçš„è¾“å…¥")
            return
    
    logger.info(f"\nâœ… å‚ä¸åˆ†é…çš„äººå‘˜ ({len(selected_assignees)} äºº): {[a['name'] for a in selected_assignees]}")
    
    # 7. è®¡ç®—å¹³å‡åˆ†é…æ–¹æ¡ˆ
    # ç»Ÿè®¡é€‰ä¸­äººå‘˜å½“å‰å·²å¼€å§‹çš„jobsæ•°é‡ï¼ˆannotated > 0 çš„ï¼Œä¸èƒ½åŠ¨ï¼‰
    assignee_workload = {}
    for a in selected_assignees:
        started = user_started_jobs.get(a['id'], 0)
        assignee_workload[a['id']] = {'name': a['name'], 'started': started, 'will_assign': 0}
    
    # è®¡ç®—æ€»jobsæ•°å’Œç›®æ ‡å¹³å‡å€¼
    total_started = sum(w['started'] for w in assignee_workload.values())
    total_jobs = total_started + len(unstarted_jobs)
    target_per_person = total_jobs // len(selected_assignees)
    remainder = total_jobs % len(selected_assignees)
    
    logger.info(f"\nğŸ“Š åˆ†é…è®¡ç®—:")
    logger.info(f"   å·²å¼€å§‹çš„Jobsï¼ˆä¸å¯åŠ¨ï¼‰: {total_started}")
    logger.info(f"   æœªå¼€å§‹çš„Jobsï¼ˆå¯åˆ†é…ï¼‰: {len(unstarted_jobs)}")
    logger.info(f"   æ€»Jobs: {total_jobs}")
    logger.info(f"   ç›®æ ‡æ¯äºº: {target_per_person} ~ {target_per_person + 1}")
    
    # è®¡ç®—æ¯ä¸ªäººçš„ç›®æ ‡æ•°é‡
    # å…ˆæŒ‰å½“å‰å·²å¼€å§‹æ•°é‡æ’åºï¼ˆå¤šçš„åœ¨å‰ï¼Œä»–ä»¬çš„ç›®æ ‡ä¼šå…ˆè¢«åˆ†é…ï¼‰
    sorted_by_started = sorted(selected_assignees, key=lambda a: user_started_jobs.get(a['id'], 0), reverse=True)
    
    targets = {}
    remaining_target = total_jobs
    remaining_people = len(selected_assignees)
    
    for a in sorted_by_started:
        started = user_started_jobs.get(a['id'], 0)
        # è¿™ä¸ªäººçš„ç›®æ ‡ = å‰©ä½™æ€»æ•° / å‰©ä½™äººæ•°ï¼ˆå‘ä¸Šå–æ•´ç»™å‰é¢çš„äººï¼‰
        avg = remaining_target // remaining_people
        extra = 1 if remaining_target % remaining_people > 0 else 0
        
        # å¦‚æœå·²å¼€å§‹çš„å·²ç»è¶…è¿‡ç›®æ ‡ï¼Œå°±åªä¿ç•™å·²å¼€å§‹çš„
        target = max(started, avg + extra)
        targets[a['id']] = target
        
        remaining_target -= target
        remaining_people -= 1
    
    # è®¡ç®—æ¯ä¸ªäººéœ€è¦åˆ†é…å¤šå°‘
    for a in selected_assignees:
        started = user_started_jobs.get(a['id'], 0)
        target = targets[a['id']]
        need = target - started
        assignee_workload[a['id']]['target'] = target
        assignee_workload[a['id']]['need'] = need
    
    # æ˜¾ç¤ºåˆ†é…é¢„è§ˆï¼ˆæŒ‰éœ€è¦åˆ†é…æ•°é‡æ’åºï¼Œå¤šçš„åœ¨å‰ï¼‰
    sorted_assignees = sorted(selected_assignees, key=lambda a: assignee_workload[a['id']]['need'], reverse=True)
    
    logger.info(f"\nğŸ“‹ åˆ†é…é¢„è§ˆ:")
    for a in sorted_assignees:
        w = assignee_workload[a['id']]
        logger.info(f"   {w['name']}: å·²å¼€å§‹ {w['started']} + å°†åˆ†é… {w['need']} = {w['target']}")
    
    # 8. ç¡®è®¤åˆ†é…
    print(f"\nç¡®è®¤æŒ‰ä¸Šè¿°æ–¹æ¡ˆåˆ†é…ï¼Ÿ(y/n): ", end='')
    confirm = input().strip().lower()
    if confirm != 'y':
        logger.info("âŒ å–æ¶ˆåˆ†é…")
        return
    
    # 9. æ‰§è¡Œåˆ†é…ï¼ˆæŒ‰éœ€åˆ†é…ç»™æ¯ä¸ªäººï¼‰
    logger.info("\nğŸš€ å¼€å§‹åˆ†é…...")
    success_count = 0
    fail_count = 0
    job_index = 0
    
    for a in sorted_assignees:
        w = assignee_workload[a['id']]
        need = w['need']
        
        for _ in range(need):
            if job_index >= len(unstarted_jobs):
                break
            job = unstarted_jobs[job_index]
            try:
                client.assign_job(job['job_id'], a['id'])
                logger.info(f"   âœ“ Job {job['job_id']} â†’ {a['name']}")
                success_count += 1
            except Exception as e:
                logger.error(f"   âœ— Job {job['job_id']} åˆ†é…å¤±è´¥: {e}")
                fail_count += 1
            job_index += 1
    
    # 10. å®Œæˆ
    logger.info("\n" + "="*60)
    logger.info(f"âœ… åˆ†é…å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {fail_count}")
    logger.info("="*60)
    logger.info(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {log_file}")


def main():
    import sys
    
    task_ids = None
    if len(sys.argv) > 1:
        try:
            task_ids = [int(tid) for tid in sys.argv[1:]]
            logger.info(f"å¤„ç†æŒ‡å®šä»»åŠ¡: {task_ids}")
        except ValueError:
            logger.error("âŒ ä»»åŠ¡IDå¿…é¡»æ˜¯æ•°å­—")
            return
    
    reassign_jobs(task_ids=task_ids)


if __name__ == "__main__":
    main()
