#!/usr/bin/env python3
"""
æ£€æŸ¥æ ‡æ³¨è¿›åº¦ - æŸ¥çœ‹æ¯ä¸ªæ ‡æ³¨äººå‘˜çš„ä»»åŠ¡å®Œæˆæƒ…å†µ
"""
import requests
import json
import logging
from pathlib import Path
from datetime import datetime
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed

# é…ç½®æ—¥å¿—
log_dir = Path('logs')
log_dir.mkdir(exist_ok=True)
log_file = log_dir / f'check_progress_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler(log_file, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class CVATClient:
    """CVATå®¢æˆ·ç«¯"""
    
    def __init__(self, base_url, api_key):
        self.base_url = base_url.rstrip('/')
        self.api_key = api_key
        self.headers = {'Authorization': f'Token {api_key}'}
        logger.info(f"åˆå§‹åŒ–CVATå®¢æˆ·ç«¯: {base_url}")
    
    def get_all_tasks(self, organization_slug=None):
        """è·å–æ‰€æœ‰ä»»åŠ¡"""
        url = f'{self.base_url}/api/tasks'
        params = {'page_size': 500}
        if organization_slug:
            params['org'] = organization_slug
        
        all_tasks = []
        page = 1
        
        try:
            while True:
                params['page'] = page
                response = requests.get(url, headers=self.headers, params=params, timeout=30)
                response.raise_for_status()
                data = response.json()
                
                results = data.get('results', [])
                all_tasks.extend(results)
                
                if not data.get('next'):
                    break
                page += 1
            
            logger.info(f"âœ… è·å–ä»»åŠ¡åˆ—è¡¨æˆåŠŸ: {len(all_tasks)} ä¸ªä»»åŠ¡")
            return all_tasks
        except requests.exceptions.RequestException as e:
            logger.error(f"âŒ è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    def get_task_jobs(self, task_id):
        """è·å–ä»»åŠ¡çš„æ‰€æœ‰jobs"""
        url = f'{self.base_url}/api/jobs'
        params = {'task_id': task_id, 'page_size': 1000}
        
        try:
            response = requests.get(url, headers=self.headers, params=params, timeout=30)
            response.raise_for_status()
            jobs_data = response.json()
            jobs = jobs_data.get('results', [])
            return jobs
        except requests.exceptions.RequestException as e:
            logger.error(f"âŒ è·å–jobså¤±è´¥: task_id={task_id}, {e}")
            return []
    
    def get_user_info(self, user_id):
        """è·å–ç”¨æˆ·ä¿¡æ¯"""
        url = f'{self.base_url}/api/users/{user_id}'
        
        try:
            response = requests.get(url, headers=self.headers, timeout=30)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            logger.error(f"âŒ è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥: user_id={user_id}, {e}")
            return None
    
    def get_organization_members(self, organization_slug):
        """è·å–ç»„ç»‡æˆå‘˜åˆ—è¡¨"""
        url = f'{self.base_url}/api/memberships'
        params = {'org': organization_slug, 'page_size': 100}
        
        try:
            response = requests.get(url, headers=self.headers, params=params, timeout=30)
            response.raise_for_status()
            data = response.json()
            members = data.get('results', [])
            return members
        except requests.exceptions.RequestException as e:
            logger.error(f"âŒ è·å–ç»„ç»‡æˆå‘˜å¤±è´¥: {e}")
            return []
    
    def get_job_annotations_count(self, job_id):
        """è·å–jobçš„æ ‡æ³¨æ•°é‡å’Œå·²æ ‡æ³¨å¸§æ•°"""
        url = f'{self.base_url}/api/jobs/{job_id}/annotations'
        
        try:
            response = requests.get(url, headers=self.headers, timeout=30)
            response.raise_for_status()
            data = response.json()
            
            shapes = data.get('shapes', [])
            tracks = data.get('tracks', [])
            
            # ç»Ÿè®¡æœ‰æ ‡æ³¨çš„å¸§ï¼ˆå»é‡ï¼‰
            annotated_frames = set()
            for shape in shapes:
                annotated_frames.add(shape.get('frame'))
            for track in tracks:
                # trackçš„shapesé‡Œä¹Ÿæœ‰frame
                for shape in track.get('shapes', []):
                    annotated_frames.add(shape.get('frame'))
            
            return len(shapes), len(tracks), len(annotated_frames)
        except requests.exceptions.Timeout:
            logger.debug(f"æ£€æŸ¥job {job_id}è¶…æ—¶")
            return 0, 0, 0
        except requests.exceptions.RequestException as e:
            logger.debug(f"æ£€æŸ¥job {job_id}å¤±è´¥: {e}")
            return 0, 0, 0


def format_duration(seconds):
    """æ ¼å¼åŒ–æ—¶é•¿"""
    if seconds is None:
        return "N/A"
    
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    
    if hours > 0:
        return f"{hours}å°æ—¶{minutes}åˆ†é’Ÿ"
    else:
        return f"{minutes}åˆ†é’Ÿ"


def check_progress(config_file='config.json', task_ids=None, show_details=False):
    """æ£€æŸ¥æ ‡æ³¨è¿›åº¦ä¸»æµç¨‹"""
    logger.info("="*60)
    logger.info("æ£€æŸ¥æ ‡æ³¨è¿›åº¦")
    logger.info("="*60)
    
    # 1. åŠ è½½é…ç½®
    logger.info("\nğŸ“– åŠ è½½é…ç½®æ–‡ä»¶...")
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
    except FileNotFoundError:
        logger.error(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        return
    
    cvat_url = config['cvat']['url']
    api_key = config['cvat']['api_key']
    organization_slug = config.get('organization', {}).get('slug')
    
    # 2. åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = CVATClient(cvat_url, api_key)
    
    # 3. è·å–ä»»åŠ¡åˆ—è¡¨
    logger.info(f"\nğŸ“‹ è·å–ä»»åŠ¡åˆ—è¡¨...")
    
    if task_ids:
        # ä½¿ç”¨æŒ‡å®šçš„ä»»åŠ¡ID
        tasks = []
        for task_id in task_ids:
            url = f'{cvat_url}/api/tasks/{task_id}'
            try:
                response = requests.get(url, headers=client.headers, timeout=30)
                response.raise_for_status()
                tasks.append(response.json())
            except Exception as e:
                logger.error(f"âŒ è·å–ä»»åŠ¡å¤±è´¥: task_id={task_id}, {e}")
    else:
        # è·å–æ‰€æœ‰ä»»åŠ¡
        tasks = client.get_all_tasks(organization_slug)
    
    # æ’é™¤æ—§å¹³å°ä»»åŠ¡
    EXCLUDED_TASKS = {1967925}
    tasks = [t for t in tasks if t['id'] not in EXCLUDED_TASKS]
    
    if not tasks:
        logger.warning("âš ï¸  æœªæ‰¾åˆ°ä»»ä½•ä»»åŠ¡")
        return
    
    logger.info(f"âœ… æ‰¾åˆ° {len(tasks)} ä¸ªä»»åŠ¡")
    
    # 4. è·å–ç»„ç»‡æˆå‘˜ä¿¡æ¯ï¼ˆç”¨äºæ˜¾ç¤ºç”¨æˆ·åï¼‰
    logger.info(f"\nğŸ‘¥ è·å–ç»„ç»‡æˆå‘˜ä¿¡æ¯...")
    members = client.get_organization_members(organization_slug) if organization_slug else []
    user_map = {}
    for member in members:
        user = member.get('user')
        if user:
            user_id = user.get('id')
            username = user.get('username')
            user_map[user_id] = username
    
    logger.info(f"âœ… æ‰¾åˆ° {len(user_map)} ä¸ªæˆå‘˜")
    
    # 5. ç»Ÿè®¡æ¯ä¸ªä»»åŠ¡çš„è¿›åº¦
    logger.info(f"\nğŸ“Š åˆ†æä»»åŠ¡è¿›åº¦...")
    
    all_stats = []
    user_stats = defaultdict(lambda: {
        'total_jobs': 0,
        'completed': 0,
        'in_progress': 0,
        'not_started': 0,
        'total_frames': 0,
        'annotated_frames': 0,
        'completed_jobs': 0,
        'total_shapes': 0,
        'speeds': []  # å­˜å‚¨æ¯ä¸ªjobçš„é€Ÿåº¦ï¼Œç”¨äºè®¡ç®—å¹³å‡
    })
    
    for task in tasks:
        task_id = task['id']
        task_name = task['name']
        task_status = task.get('status')
        created_date = task.get('created_date', '')[:10]
        
        logger.info(f"\nå¤„ç†ä»»åŠ¡: {task_name} (ID: {task_id})")
        
        # è·å–ä»»åŠ¡çš„jobs
        jobs = client.get_task_jobs(task_id)
        
        if not jobs:
            logger.info(f"   â†’ æ²¡æœ‰jobs")
            continue
        
        logger.info(f"   â†’ Jobsæ•°: {len(jobs)}")
        logger.info(f"   â†’ æ£€æŸ¥æ ‡æ³¨çŠ¶æ€ï¼ˆå¹¶å‘ï¼‰...")
        
        # å¹¶å‘æ£€æŸ¥æ¯ä¸ªjobçš„æ ‡æ³¨æ•°é‡
        def check_job(job):
            job_id = job.get('id')
            start_frame = job.get('start_frame', 0)
            stop_frame = job.get('stop_frame', 0)
            frame_count = stop_frame - start_frame + 1
            shapes, tracks, annotated_frames = client.get_job_annotations_count(job_id)
            return job_id, shapes, tracks, annotated_frames, frame_count
        
        job_annotations = {}
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = {executor.submit(check_job, job): job for job in jobs}
            completed = 0
            for future in as_completed(futures):
                job_id, shapes, tracks, annotated_frames, frame_count = future.result()
                job_annotations[job_id] = {
                    'shapes': shapes, 
                    'tracks': tracks, 
                    'annotated_frames': annotated_frames,
                    'frame_count': frame_count
                }
                completed += 1
                if completed % 10 == 0 or completed == len(jobs):
                    logger.info(f"      è¿›åº¦: {completed}/{len(jobs)} jobs")
        
        # ç»Ÿè®¡ä»»åŠ¡çº§åˆ«çš„ä¿¡æ¯
        task_stats = {
            'task_id': task_id,
            'task_name': task_name,
            'task_status': task_status,
            'created_date': created_date,
            'total_jobs': len(jobs),
            'job_stats': defaultdict(int),
            'assignee_stats': defaultdict(lambda: defaultdict(int)),
            'total_frames': 0,
            'completed_frames': 0
        }
        
        for job in jobs:
            job_id = job['id']
            state = job.get('state', 'new')
            assignee = job.get('assignee')
            start_frame = job.get('start_frame', 0)
            stop_frame = job.get('stop_frame', 0)
            frame_count = stop_frame - start_frame + 1
            
            # è·å–æ ‡æ³¨æ•°é‡
            ann_info = job_annotations.get(job_id, {'shapes': 0, 'tracks': 0, 'annotated_frames': 0, 'frame_count': frame_count})
            shapes_count = ann_info['shapes']
            tracks_count = ann_info['tracks']
            annotated_frames = ann_info['annotated_frames']
            
            # ç»Ÿè®¡jobçŠ¶æ€ï¼ˆåŸºäºå·²æ ‡æ³¨å¸§æ•°åˆ¤æ–­ï¼‰
            if annotated_frames == 0:
                actual_state = 'not_started'
            elif annotated_frames >= frame_count:
                actual_state = 'completed'
            else:
                actual_state = 'in_progress'
            
            task_stats['job_stats'][actual_state] += 1
            task_stats['total_frames'] += frame_count
            
            # è®¡å…¥å·²æ ‡æ³¨å¸§æ•°ï¼ˆç²¾ç¡®ç»Ÿè®¡ï¼‰
            task_stats['completed_frames'] += annotated_frames
            
            # ç»Ÿè®¡æ¯ä¸ªæ ‡æ³¨äººå‘˜çš„æƒ…å†µ
            if assignee:
                assignee_id = assignee.get('id')
                assignee_username = assignee.get('username')
                assignee_name = user_map.get(assignee_id, assignee_username or f"User_{assignee_id}")
                
                task_stats['assignee_stats'][assignee_name]['total'] += 1
                task_stats['assignee_stats'][assignee_name][actual_state] += 1
                task_stats['assignee_stats'][assignee_name]['frames'] += frame_count
                task_stats['assignee_stats'][assignee_name]['annotated_frames'] = \
                    task_stats['assignee_stats'][assignee_name].get('annotated_frames', 0) + annotated_frames
                task_stats['assignee_stats'][assignee_name]['shapes'] = \
                    task_stats['assignee_stats'][assignee_name].get('shapes', 0) + shapes_count
                
                # è®¡ç®—é€Ÿåº¦ï¼ˆå¸§/å°æ—¶ï¼‰
                assigned_date = job.get('assignee_updated_date') or job.get('created_date')
                updated_date = job.get('updated_date')
                if assigned_date and updated_date and annotated_frames > 0:
                    try:
                        from datetime import datetime as dt
                        assigned_dt = dt.fromisoformat(assigned_date.replace('Z', '+00:00'))
                        updated_dt = dt.fromisoformat(updated_date.replace('Z', '+00:00'))
                        hours = (updated_dt - assigned_dt).total_seconds() / 3600
                        if hours > 0:
                            speed = annotated_frames / hours
                            user_stats[assignee_name]['speeds'].append(speed)
                    except:
                        pass
                
                # å…¨å±€ç»Ÿè®¡
                user_stats[assignee_name]['total_jobs'] += 1
                user_stats[assignee_name][actual_state] += 1
                user_stats[assignee_name]['total_frames'] += frame_count
                user_stats[assignee_name]['annotated_frames'] = \
                    user_stats[assignee_name].get('annotated_frames', 0) + annotated_frames
                user_stats[assignee_name]['total_shapes'] = \
                    user_stats[assignee_name].get('total_shapes', 0) + shapes_count
                
                # å®Œæˆçš„jobæ•°
                if actual_state == 'completed':
                    user_stats[assignee_name]['completed_jobs'] = \
                        user_stats[assignee_name].get('completed_jobs', 0) + 1
        
        all_stats.append(task_stats)
    
    # 6. æ˜¾ç¤ºç»“æœ
    logger.info("\n" + "="*80)
    logger.info("ğŸ“Š ä»»åŠ¡è¿›åº¦æ±‡æ€»")
    logger.info("="*80)
    
    for task_stat in all_stats:
        logger.info(f"\nğŸ“Œ ä»»åŠ¡: {task_stat['task_name']} (ID: {task_stat['task_id']})")
        logger.info(f"   åˆ›å»ºæ—¥æœŸ: {task_stat['created_date']}")
        logger.info(f"   ä»»åŠ¡çŠ¶æ€: {task_stat['task_status']}")
        logger.info(f"   æ€»Jobsæ•°: {task_stat['total_jobs']}")
        logger.info(f"   æ€»å¸§æ•°: {task_stat['total_frames']}")
        logger.info(f"   å·²æ ‡æ³¨å¸§: {task_stat['completed_frames']} ({task_stat['completed_frames']*100//task_stat['total_frames'] if task_stat['total_frames'] > 0 else 0}%)")
        
        # JobçŠ¶æ€åˆ†å¸ƒ
        logger.info(f"\n   JobçŠ¶æ€åˆ†å¸ƒ:")
        for state, count in sorted(task_stat['job_stats'].items()):
            percentage = count * 100 // task_stat['total_jobs'] if task_stat['total_jobs'] > 0 else 0
            logger.info(f"     - {state}: {count} ({percentage}%)")
        
        # æ ‡æ³¨äººå‘˜ç»Ÿè®¡
        if task_stat['assignee_stats']:
            logger.info(f"\n   æ ‡æ³¨äººå‘˜è¿›åº¦:")
            for assignee, stats in sorted(task_stat['assignee_stats'].items()):
                total = stats['total']
                completed = stats.get('completed', 0)
                in_progress = stats.get('in_progress', 0)
                not_started = stats.get('not_started', 0)
                frames = stats.get('frames', 0)
                annotated_frames = stats.get('annotated_frames', 0)
                shapes = stats.get('shapes', 0)
                
                frame_rate = annotated_frames * 100 // frames if frames > 0 else 0
                
                logger.info(f"     ğŸ‘¤ {assignee}:")
                logger.info(f"        Jobs: {completed}å®Œæˆ/{in_progress}è¿›è¡Œä¸­/{not_started}æœªå¼€å§‹ (å…±{total})")
                logger.info(f"        å¸§æ•°: {annotated_frames}/{frames} ({frame_rate}%) | æ ‡æ³¨æ•°: {shapes}")
    
    # 7. å…¨å±€æ ‡æ³¨äººå‘˜ç»Ÿè®¡
    logger.info("\n" + "="*80)
    logger.info("ğŸ‘¥ æ ‡æ³¨äººå‘˜æ€»ä½“è¿›åº¦")
    logger.info("="*80)
    
    if user_stats:
        # æŒ‰å®Œæˆç‡æ’åº
        sorted_users = sorted(
            user_stats.items(),
            key=lambda x: x[1].get('annotated_frames', 0) / x[1]['total_frames'] if x[1]['total_frames'] > 0 else 0,
            reverse=True
        )
        
        for assignee, stats in sorted_users:
            total = stats['total_jobs']
            completed_jobs = stats.get('completed_jobs', 0)
            in_progress = stats.get('in_progress', 0)
            not_started = stats.get('not_started', 0)
            total_frames = stats['total_frames']
            annotated_frames = stats.get('annotated_frames', 0)
            total_shapes = stats.get('total_shapes', 0)
            speeds = stats.get('speeds', [])
            avg_speed = sum(speeds) / len(speeds) if speeds else None
            
            frame_completion_rate = annotated_frames * 100 // total_frames if total_frames > 0 else 0
            
            logger.info(f"\nğŸ‘¤ {assignee}:")
            logger.info(f"   Jobs: {completed_jobs}å®Œæˆ/{in_progress}è¿›è¡Œä¸­/{not_started}æœªå¼€å§‹ (å…±{total})")
            logger.info(f"   å¸§æ•°: {annotated_frames}/{total_frames} ({frame_completion_rate}%)")
            logger.info(f"   æ ‡æ³¨æ•°: {total_shapes}")
            logger.info(f"   å¹³å‡é€Ÿåº¦: {avg_speed:.1f} å¸§/å°æ—¶" if avg_speed else "   å¹³å‡é€Ÿåº¦: N/A")
            
            # è¿›åº¦æ¡ï¼ˆåŸºäºå¸§å®Œæˆç‡ï¼‰
            bar_length = 40
            filled = int(bar_length * frame_completion_rate / 100)
            bar = 'â–ˆ' * filled + 'â–‘' * (bar_length - filled)
            logger.info(f"   è¿›åº¦: [{bar}] {frame_completion_rate}%")
    else:
        sorted_users = []
        logger.info("   æœªæ‰¾åˆ°å·²åˆ†é…çš„ä»»åŠ¡")
    
    # 8. ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    report_file = log_dir / f'progress_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
    
    report = {
        'generated_at': datetime.now().isoformat(),
        'summary': {
            'total_tasks': len(all_stats),
            'total_users': len(user_stats)
        },
        'tasks': all_stats,
        'users': dict(user_stats)
    }
    
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False, default=str)
    
    logger.info(f"\nâœ… è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    logger.info(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {log_file}")
    
    # 9. ç”Ÿæˆç®€å•çš„æ¯æ—¥æŠ¥å‘Š
    daily_report_file = log_dir / f'daily_report_{datetime.now().strftime("%Y%m%d")}.txt'
    
    with open(daily_report_file, 'w', encoding='utf-8') as f:
        f.write(f"æ ‡æ³¨è¿›åº¦æ—¥æŠ¥ - {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}\n")
        f.write("="*60 + "\n\n")
        
        f.write("ğŸ“Š æ€»ä½“æƒ…å†µ\n")
        f.write(f"  ä»»åŠ¡æ•°: {len(all_stats)}\n")
        f.write(f"  æ ‡æ³¨äººå‘˜: {len(user_stats)}\n\n")
        
        f.write("ğŸ‘¥ æ ‡æ³¨äººå‘˜è¿›åº¦\n")
        f.write("-"*60 + "\n")
        
        for assignee, stats in sorted_users:
            total = stats['total_jobs']
            completed_jobs = stats.get('completed_jobs', 0)
            in_progress = stats.get('in_progress', 0)
            not_started = stats.get('not_started', 0)
            total_frames = stats['total_frames']
            annotated_frames = stats.get('annotated_frames', 0)
            total_shapes = stats.get('total_shapes', 0)
            
            frame_rate = annotated_frames * 100 // total_frames if total_frames > 0 else 0
            
            f.write(f"\n{assignee}:\n")
            f.write(f"  Jobs: {completed_jobs}å®Œæˆ/{in_progress}è¿›è¡Œä¸­/{not_started}æœªå¼€å§‹ (å…±{total})\n")
            f.write(f"  å¸§æ•°: {annotated_frames}/{total_frames} ({frame_rate}%)\n")
            f.write(f"  æ ‡æ³¨æ•°: {total_shapes}\n")
        
        f.write("\n" + "="*60 + "\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    logger.info(f"ğŸ“„ æ¯æ—¥æŠ¥å‘Šå·²ä¿å­˜: {daily_report_file}")
    
    logger.info("\n" + "="*80)


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    import sys
    
    task_ids = None
    if len(sys.argv) > 1:
        # æ”¯æŒæŒ‡å®šä»»åŠ¡ID
        try:
            task_ids = [int(tid) for tid in sys.argv[1:]]
            logger.info(f"æ£€æŸ¥æŒ‡å®šä»»åŠ¡: {task_ids}")
        except ValueError:
            logger.error("âŒ ä»»åŠ¡IDå¿…é¡»æ˜¯æ•°å­—")
            logger.info("ç”¨æ³•: python check_progress.py [task_id1] [task_id2] ...")
            return
    
    check_progress(task_ids=task_ids)


if __name__ == "__main__":
    main()
