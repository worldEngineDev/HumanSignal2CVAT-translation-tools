#!/usr/bin/env python3
"""
å¯¼å…¥é¢„æ ‡æ³¨åˆ°CVAT
ä»äº‘å­˜å‚¨è¯»å– *_bbox.json (COCOæ ¼å¼)ï¼Œè½¬æ¢å¹¶å¯¼å…¥åˆ°å¯¹åº”çš„ job
åªå¯¹æ²¡æœ‰æ ‡æ³¨çš„ job å¯¼å…¥ï¼Œä¸è¦†ç›–äººå·¥æ ‡æ³¨
"""
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import json
import logging
import boto3
import re
from pathlib import Path
from datetime import datetime
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed

# é…ç½®å¸¦é‡è¯•çš„ session
def get_retry_session():
    session = requests.Session()
    retry = Retry(total=3, backoff_factor=1, status_forcelist=[500, 502, 503, 504])
    adapter = HTTPAdapter(max_retries=retry)
    session.mount('http://', adapter)
    session.mount('https://', adapter)
    return session

# é…ç½®æ—¥å¿—
log_dir = Path('logs')
log_dir.mkdir(exist_ok=True)
log_file = log_dir / f'import_preannotations_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler(log_file, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# æ’é™¤çš„ä»»åŠ¡
EXCLUDED_TASKS = {1967925}

# é¢„æ ‡æ³¨è®°å½•ç›®å½•
report_dir = Path('reports')
report_dir.mkdir(exist_ok=True)
preannotation_record_file = report_dir / 'preannotation_records.json'

def load_preannotation_records():
    """åŠ è½½é¢„æ ‡æ³¨è®°å½•"""
    if preannotation_record_file.exists():
        with open(preannotation_record_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

def save_preannotation_records(records):
    """ä¿å­˜é¢„æ ‡æ³¨è®°å½•"""
    with open(preannotation_record_file, 'w', encoding='utf-8') as f:
        json.dump(records, f, indent=2, ensure_ascii=False)

# æ ‡ç­¾æ˜ å°„ï¼šCOCO -> CVAT
LABEL_MAP = {
    'left_hand': 'Left hand',
    'right_hand': 'Right hand',
    'partial_left_hand': 'Partial left hand',
    'partial_right_hand': 'Partial right hand',
}


class CVATClient:
    """CVATå®¢æˆ·ç«¯"""
    
    def __init__(self, base_url, api_key):
        self.base_url = base_url.rstrip('/')
        self.api_key = api_key
        self.headers = {'Authorization': f'Token {api_key}'}
        self.session = get_retry_session()
    
    def get_task(self, task_id):
        """è·å–ä»»åŠ¡ä¿¡æ¯"""
        url = f'{self.base_url}/api/tasks/{task_id}'
        response = self.session.get(url, headers=self.headers, timeout=30)
        response.raise_for_status()
        return response.json()
    
    def get_task_jobs(self, task_id):
        """è·å–ä»»åŠ¡çš„æ‰€æœ‰jobs"""
        url = f'{self.base_url}/api/jobs'
        params = {'task_id': task_id, 'page_size': 1000}
        response = self.session.get(url, headers=self.headers, params=params, timeout=30)
        response.raise_for_status()
        return response.json().get('results', [])
    
    def get_job_frames(self, job_id):
        """è·å–jobçš„å¸§ä¿¡æ¯ï¼ˆå›¾ç‰‡è·¯å¾„ï¼‰"""
        url = f'{self.base_url}/api/jobs/{job_id}/data/meta'
        response = self.session.get(url, headers=self.headers, timeout=60)
        response.raise_for_status()
        return response.json()
    
    def get_job_annotations_count(self, job_id):
        """è·å–jobçš„å·²æ ‡æ³¨å¸§æ•°"""
        url = f'{self.base_url}/api/jobs/{job_id}/annotations'
        try:
            response = self.session.get(url, headers=self.headers, timeout=30)
            response.raise_for_status()
            data = response.json()
            annotated_frames = set()
            for shape in data.get('shapes', []):
                annotated_frames.add(shape.get('frame'))
            return len(annotated_frames)
        except:
            return -1
    
    def get_task_labels(self, task_id):
        """è·å–ä»»åŠ¡çš„æ ‡ç­¾åˆ—è¡¨"""
        url = f'{self.base_url}/api/labels'
        params = {'task_id': task_id}
        response = self.session.get(url, headers=self.headers, params=params, timeout=30)
        response.raise_for_status()
        data = response.json()
        
        labels = {}
        for label in data.get('results', []):
            labels[label['name']] = label['id']
        return labels
    
    def upload_job_annotations(self, job_id, annotations):
        """ä¸Šä¼ æ ‡æ³¨åˆ°job"""
        url = f'{self.base_url}/api/jobs/{job_id}/annotations?action=create'
        headers = {**self.headers, 'Content-Type': 'application/json'}
        
        response = self.session.patch(url, headers=headers, json=annotations, timeout=120)
        response.raise_for_status()
        return True


class S3Client:
    """S3/R2å®¢æˆ·ç«¯"""
    
    def __init__(self, config):
        endpoint_url = f"https://{config['account_id']}.r2.cloudflarestorage.com"
        self.s3 = boto3.client('s3',
            endpoint_url=endpoint_url,
            aws_access_key_id=config['aws_access_key_id'],
            aws_secret_access_key=config['aws_secret_access_key'],
            region_name=config['region']
        )
        self.bucket = config['bucket_name']
    
    def get_json(self, key):
        """ä¸‹è½½å¹¶è§£æJSONæ–‡ä»¶"""
        try:
            resp = self.s3.get_object(Bucket=self.bucket, Key=key)
            return json.loads(resp['Body'].read().decode('utf-8'))
        except Exception as e:
            logger.debug(f"è·å–JSONå¤±è´¥: {key}, {e}")
            return None
    
    def find_bbox_json(self, prefix):
        """åœ¨æŒ‡å®šå‰ç¼€ä¸‹æŸ¥æ‰¾ *_bbox.json æ–‡ä»¶"""
        try:
            resp = self.s3.list_objects_v2(Bucket=self.bucket, Prefix=prefix, MaxKeys=100)
            for obj in resp.get('Contents', []):
                if obj['Key'].endswith('_bbox.json'):
                    return obj['Key']
        except:
            pass
        return None



def extract_chunk_id(filename):
    """
    ä»æ–‡ä»¶è·¯å¾„æå– chunk ID
    æ ¼å¼: 23dc/session_20260121_200123_268461/0001/down/labels/.../frame_00000.jpg
    è¿”å›: session_20260121_200123_268461_0001
    """
    parts = filename.split('/')
    for i, part in enumerate(parts):
        if part.startswith('session_'):
            if i + 1 < len(parts):
                chunk_num = parts[i + 1]
                return f"{part}_{chunk_num}"
    return None


def get_session_prefix(filename):
    """
    ä»æ–‡ä»¶è·¯å¾„è·å– session çš„ labels ç›®å½•å‰ç¼€
    æ ¼å¼: 23dc/session_20260121_200123_268461/0001/down/labels/.../frame_00000.jpg
    è¿”å›: 23dc/session_20260121_200123_268461/0001/down/labels/
    """
    parts = filename.split('/')
    for i, part in enumerate(parts):
        if part == 'labels' and i > 0:
            return '/'.join(parts[:i+1]) + '/'
    return None


def convert_coco_to_cvat(coco_data, frame_mapping, label_ids, start_frame):
    """
    å°†COCOæ ¼å¼è½¬æ¢ä¸ºCVATæ ¼å¼
    
    coco_data: COCO JSONæ•°æ®
    frame_mapping: {coco_image_id: cvat_frame_number}
    label_ids: {label_name: label_id}
    start_frame: jobçš„èµ·å§‹å¸§å·
    """
    shapes = []
    
    # æ„å»º category_id -> label_name æ˜ å°„
    category_map = {}
    for cat in coco_data.get('categories', []):
        category_map[cat['id']] = cat['name']
    
    # æ„å»º image_id -> file_name æ˜ å°„
    image_map = {}
    for img in coco_data.get('images', []):
        image_map[img['id']] = img['file_name']
    
    for ann in coco_data.get('annotations', []):
        image_id = ann['image_id']
        category_id = ann['category_id']
        bbox = ann['bbox']  # [x, y, width, height]
        
        # è·å–æ ‡ç­¾åç§°
        coco_label = category_map.get(category_id)
        if not coco_label:
            continue
        
        # æ˜ å°„åˆ°CVATæ ‡ç­¾
        cvat_label = LABEL_MAP.get(coco_label, coco_label)
        label_id = label_ids.get(cvat_label)
        if not label_id:
            logger.warning(f"æ ‡ç­¾æœªæ‰¾åˆ°: {cvat_label}")
            continue
        
        # è·å–å¸§å·
        if image_id not in frame_mapping:
            continue
        
        frame = frame_mapping[image_id]
        
        # CVAT rectangle æ ¼å¼: [x1, y1, x2, y2]
        x, y, w, h = bbox
        points = [x, y, x + w, y + h]
        
        shapes.append({
            'type': 'rectangle',
            'frame': frame,
            'label_id': label_id,
            'points': points,
            'occluded': False,
            'z_order': 0,
            'attributes': []
        })
    
    return {'shapes': shapes, 'tracks': [], 'tags': []}


def import_preannotations(config_file='config.json', task_id=None, job_id=None):
    """å¯¼å…¥é¢„æ ‡æ³¨ä¸»æµç¨‹
    
    Args:
        task_id: ä»»åŠ¡ID
        job_id: å¯é€‰ï¼ŒæŒ‡å®šå•ä¸ªjobå¯¼å…¥
    """
    logger.info("="*60)
    logger.info("å¯¼å…¥é¢„æ ‡æ³¨åˆ°CVAT")
    logger.info("="*60)
    
    # 1. åŠ è½½é…ç½®
    logger.info("\nğŸ“– åŠ è½½é…ç½®æ–‡ä»¶...")
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
    except FileNotFoundError:
        logger.error(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        return
    
    cvat_url = config['cvat']['url']
    api_key = config['cvat']['api_key']
    s3_config = config['s3']
    
    cvat = CVATClient(cvat_url, api_key)
    s3 = S3Client(s3_config)
    
    # åŠ è½½å·²æœ‰çš„é¢„æ ‡æ³¨è®°å½•
    preannotation_records = load_preannotation_records()
    
    # 2. è·å–ä»»åŠ¡ä¿¡æ¯
    if not task_id:
        logger.error("âŒ è¯·æŒ‡å®šä»»åŠ¡ID")
        return
    
    logger.info(f"\nğŸ“‹ è·å–ä»»åŠ¡ä¿¡æ¯: {task_id}")
    try:
        task = cvat.get_task(task_id)
        logger.info(f"   ä»»åŠ¡åç§°: {task['name']}")
    except Exception as e:
        logger.error(f"âŒ è·å–ä»»åŠ¡å¤±è´¥: {e}")
        return
    
    # 3. è·å–ä»»åŠ¡æ ‡ç­¾
    label_ids = cvat.get_task_labels(task_id)
    logger.info(f"   æ ‡ç­¾: {list(label_ids.keys())}")
    
    # 4. è·å–æ‰€æœ‰jobs
    jobs = cvat.get_task_jobs(task_id)
    logger.info(f"   Jobsæ•°: {len(jobs)}")
    
    # å¦‚æœæŒ‡å®šäº†job_idï¼Œåªå¤„ç†è¯¥job
    if job_id:
        jobs = [j for j in jobs if j['id'] == job_id]
        if not jobs:
            logger.error(f"âŒ æœªæ‰¾åˆ°Job: {job_id}")
            return
        logger.info(f"   æŒ‡å®šå¤„ç†Job: {job_id}")
    
    # 5. å¤„ç†æ¯ä¸ªjob
    success_count = 0
    skip_count = 0
    fail_count = 0
    
    for job in jobs:
        job_id = job['id']
        start_frame = job.get('start_frame', 0)
        stop_frame = job.get('stop_frame', 0)
        
        logger.info(f"\nå¤„ç† Job {job_id} (å¸§ {start_frame}-{stop_frame})...")
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ ‡æ³¨
        annotated_count = cvat.get_job_annotations_count(job_id)
        if annotated_count > 0:
            logger.info(f"   â­ï¸  è·³è¿‡ï¼šå·²æœ‰ {annotated_count} å¸§æ ‡æ³¨")
            skip_count += 1
            continue
        
        # è·å–jobçš„å¸§ä¿¡æ¯
        try:
            meta = cvat.get_job_frames(job_id)
            frames = meta.get('frames', [])
            if not frames:
                logger.warning(f"   âš ï¸  æ— å¸§ä¿¡æ¯")
                fail_count += 1
                continue
        except Exception as e:
            logger.error(f"   âŒ è·å–å¸§ä¿¡æ¯å¤±è´¥: {e}")
            fail_count += 1
            continue
        
        # ä»ç¬¬ä¸€å¸§è·¯å¾„è·å–sessionå‰ç¼€
        first_frame_path = frames[0].get('name', '')
        session_prefix = get_session_prefix(first_frame_path)
        
        if not session_prefix:
            logger.warning(f"   âš ï¸  æ— æ³•è§£æsessionè·¯å¾„: {first_frame_path}")
            fail_count += 1
            continue
        
        logger.info(f"   Session: {session_prefix}")
        
        # æŸ¥æ‰¾bbox.json
        bbox_json_key = s3.find_bbox_json(session_prefix)
        if not bbox_json_key:
            logger.warning(f"   âš ï¸  æœªæ‰¾åˆ°é¢„æ ‡æ³¨æ–‡ä»¶")
            fail_count += 1
            continue
        
        logger.info(f"   é¢„æ ‡æ³¨æ–‡ä»¶: {bbox_json_key}")
        
        # ä¸‹è½½COCOæ•°æ®
        coco_data = s3.get_json(bbox_json_key)
        if not coco_data:
            logger.error(f"   âŒ ä¸‹è½½é¢„æ ‡æ³¨å¤±è´¥")
            fail_count += 1
            continue
        
        # æ„å»ºå¸§æ˜ å°„: COCO image_id -> CVAT frame
        # COCOçš„imageæŒ‰file_nameæ’åºï¼ŒCVATçš„frameæŒ‰é¡ºåº
        frame_mapping = {}
        coco_images = {img['file_name']: img['id'] for img in coco_data.get('images', [])}
        
        for idx, frame_info in enumerate(frames):
            frame_name = frame_info.get('name', '')
            cvat_frame = start_frame + idx
            
            # åœ¨COCOä¸­æŸ¥æ‰¾å¯¹åº”çš„image
            if frame_name in coco_images:
                coco_image_id = coco_images[frame_name]
                frame_mapping[coco_image_id] = cvat_frame
        
        logger.info(f"   å¸§æ˜ å°„: {len(frame_mapping)}/{len(frames)}")
        
        if not frame_mapping:
            logger.warning(f"   âš ï¸  æ— æ³•å»ºç«‹å¸§æ˜ å°„")
            fail_count += 1
            continue
        
        # è½¬æ¢æ ¼å¼
        cvat_annotations = convert_coco_to_cvat(coco_data, frame_mapping, label_ids, start_frame)
        shapes_count = len(cvat_annotations['shapes'])
        
        if shapes_count == 0:
            logger.info(f"   â„¹ï¸  é¢„æ ‡æ³¨ä¸ºç©º")
            skip_count += 1
            continue
        
        logger.info(f"   è½¬æ¢å®Œæˆ: {shapes_count} ä¸ªæ ‡æ³¨")
        
        # ä¸Šä¼ åˆ°CVAT
        try:
            cvat.upload_job_annotations(job_id, cvat_annotations)
            logger.info(f"   âœ… å¯¼å…¥æˆåŠŸ")
            success_count += 1
            
            # è®°å½•é¢„æ ‡æ³¨ä¿¡æ¯
            preannotation_records[str(job_id)] = {
                'task_id': task_id,
                'shapes_count': shapes_count,
                'frames_count': len(frame_mapping),
                'imported_at': datetime.now().isoformat(),
                'bbox_json': bbox_json_key
            }
        except Exception as e:
            logger.error(f"   âŒ å¯¼å…¥å¤±è´¥: {e}")
            fail_count += 1
    
    # 6. ä¿å­˜é¢„æ ‡æ³¨è®°å½•
    if preannotation_records:
        save_preannotation_records(preannotation_records)
        logger.info(f"\nğŸ“‹ é¢„æ ‡æ³¨è®°å½•å·²ä¿å­˜: {preannotation_record_file}")
    
    # 7. å®Œæˆ
    logger.info("\n" + "="*60)
    logger.info(f"âœ… å¯¼å…¥å®Œæˆ")
    logger.info(f"   æˆåŠŸ: {success_count}")
    logger.info(f"   è·³è¿‡: {skip_count}")
    logger.info(f"   å¤±è´¥: {fail_count}")
    logger.info("="*60)
    logger.info(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {log_file}")


def main():
    import sys
    
    task_id = None
    job_id = None
    
    # è§£æå‚æ•°
    args = sys.argv[1:]
    i = 0
    while i < len(args):
        if args[i] == '--job' and i + 1 < len(args):
            job_id = int(args[i + 1])
            i += 2
        else:
            task_id = int(args[i])
            i += 1
    
    if not task_id:
        print("âŒ è¯·æŒ‡å®šä»»åŠ¡ID")
        print("ç”¨æ³•: python import_preannotations.py <task_id> [--job <job_id>]")
        print("ç¤ºä¾‹: python import_preannotations.py 1972398")
        print("ç¤ºä¾‹: python import_preannotations.py 1972398 --job 3541585")
        return
    
    import_preannotations(task_id=task_id, job_id=job_id)


if __name__ == "__main__":
    main()
