#!/usr/bin/env python3
"""
æ£€æŸ¥æ ‡æ³¨è¿›åº¦ - æŸ¥çœ‹æ¯ä¸ªæ ‡æ³¨äººå‘˜çš„ä»»åŠ¡å®Œæˆæƒ…å†µ
"""
import requests
import json
import logging
from pathlib import Path
from datetime import datetime
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed

# é…ç½®æ—¥å¿—
log_dir = Path('logs')
log_dir.mkdir(exist_ok=True)
log_file = log_dir / f'check_progress_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler(log_file, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class CVATClient:
    """CVATå®¢æˆ·ç«¯"""
    
    def __init__(self, base_url, api_key):
        self.base_url = base_url.rstrip('/')
        self.api_key = api_key
        self.headers = {'Authorization': f'Token {api_key}'}
        logger.info(f"åˆå§‹åŒ–CVATå®¢æˆ·ç«¯: {base_url}")
    
    def get_all_tasks(self, organization_slug=None):
        """è·å–æ‰€æœ‰ä»»åŠ¡"""
        url = f'{self.base_url}/api/tasks'
        params = {'page_size': 500}
        if organization_slug:
            params['org'] = organization_slug
        
        all_tasks = []
        page = 1
        
        try:
            while True:
                params['page'] = page
                response = requests.get(url, headers=self.headers, params=params, timeout=30)
                response.raise_for_status()
                data = response.json()
                
                results = data.get('results', [])
                all_tasks.extend(results)
                
                if not data.get('next'):
                    break
                page += 1
            
            logger.info(f"âœ… è·å–ä»»åŠ¡åˆ—è¡¨æˆåŠŸ: {len(all_tasks)} ä¸ªä»»åŠ¡")
            return all_tasks
        except requests.exceptions.RequestException as e:
            logger.error(f"âŒ è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    def get_task_jobs(self, task_id):
        """è·å–ä»»åŠ¡çš„æ‰€æœ‰jobs"""
        url = f'{self.base_url}/api/jobs'
        params = {'task_id': task_id, 'page_size': 1000}
        
        try:
            response = requests.get(url, headers=self.headers, params=params, timeout=30)
            response.raise_for_status()
            jobs_data = response.json()
            jobs = jobs_data.get('results', [])
            return jobs
        except requests.exceptions.RequestException as e:
            logger.error(f"âŒ è·å–jobså¤±è´¥: task_id={task_id}, {e}")
            return []
    
    def get_user_info(self, user_id):
        """è·å–ç”¨æˆ·ä¿¡æ¯"""
        url = f'{self.base_url}/api/users/{user_id}'
        
        try:
            response = requests.get(url, headers=self.headers, timeout=30)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            logger.error(f"âŒ è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥: user_id={user_id}, {e}")
            return None
    
    def get_organization_members(self, organization_slug):
        """è·å–ç»„ç»‡æˆå‘˜åˆ—è¡¨"""
        url = f'{self.base_url}/api/memberships'
        params = {'org': organization_slug, 'page_size': 100}
        
        try:
            response = requests.get(url, headers=self.headers, params=params, timeout=30)
            response.raise_for_status()
            data = response.json()
            members = data.get('results', [])
            return members
        except requests.exceptions.RequestException as e:
            logger.error(f"âŒ è·å–ç»„ç»‡æˆå‘˜å¤±è´¥: {e}")
            return []
    
    def get_job_has_annotations(self, job_id):
        """æ£€æŸ¥jobæ˜¯å¦æœ‰æ ‡æ³¨ï¼ˆåªæ£€æŸ¥æ•°é‡ï¼Œä¸è·å–å…¨éƒ¨æ•°æ®ï¼‰"""
        url = f'{self.base_url}/api/jobs/{job_id}/annotations'
        
        try:
            # åªè·å–ç¬¬ä¸€é¡µï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
            response = requests.get(url, headers=self.headers, params={'page_size': 1}, timeout=30)
            response.raise_for_status()
            data = response.json()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰shapesæˆ–tracks
            has_shapes = len(data.get('shapes', [])) > 0
            has_tracks = len(data.get('tracks', [])) > 0
            
            return has_shapes or has_tracks
        except requests.exceptions.Timeout:
            logger.debug(f"æ£€æŸ¥job {job_id}è¶…æ—¶")
            return False
        except requests.exceptions.RequestException as e:
            logger.debug(f"æ£€æŸ¥job {job_id}å¤±è´¥: {e}")
            return False


def format_duration(seconds):
    """æ ¼å¼åŒ–æ—¶é•¿"""
    if seconds is None:
        return "N/A"
    
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    
    if hours > 0:
        return f"{hours}å°æ—¶{minutes}åˆ†é’Ÿ"
    else:
        return f"{minutes}åˆ†é’Ÿ"


def check_progress(config_file='config.json', task_ids=None, show_details=False):
    """æ£€æŸ¥æ ‡æ³¨è¿›åº¦ä¸»æµç¨‹"""
    logger.info("="*60)
    logger.info("æ£€æŸ¥æ ‡æ³¨è¿›åº¦")
    logger.info("="*60)
    
    # 1. åŠ è½½é…ç½®
    logger.info("\nğŸ“– åŠ è½½é…ç½®æ–‡ä»¶...")
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
    except FileNotFoundError:
        logger.error(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        return
    
    cvat_url = config['cvat']['url']
    api_key = config['cvat']['api_key']
    organization_slug = config.get('organization', {}).get('slug')
    
    # 2. åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = CVATClient(cvat_url, api_key)
    
    # 3. è·å–ä»»åŠ¡åˆ—è¡¨
    logger.info(f"\nğŸ“‹ è·å–ä»»åŠ¡åˆ—è¡¨...")
    
    if task_ids:
        # ä½¿ç”¨æŒ‡å®šçš„ä»»åŠ¡ID
        tasks = []
        for task_id in task_ids:
            url = f'{cvat_url}/api/tasks/{task_id}'
            try:
                response = requests.get(url, headers=client.headers, timeout=30)
                response.raise_for_status()
                tasks.append(response.json())
            except Exception as e:
                logger.error(f"âŒ è·å–ä»»åŠ¡å¤±è´¥: task_id={task_id}, {e}")
    else:
        # è·å–æ‰€æœ‰ä»»åŠ¡
        tasks = client.get_all_tasks(organization_slug)
    
    if not tasks:
        logger.warning("âš ï¸  æœªæ‰¾åˆ°ä»»ä½•ä»»åŠ¡")
        return
    
    logger.info(f"âœ… æ‰¾åˆ° {len(tasks)} ä¸ªä»»åŠ¡")
    
    # 4. è·å–ç»„ç»‡æˆå‘˜ä¿¡æ¯ï¼ˆç”¨äºæ˜¾ç¤ºç”¨æˆ·åï¼‰
    logger.info(f"\nğŸ‘¥ è·å–ç»„ç»‡æˆå‘˜ä¿¡æ¯...")
    members = client.get_organization_members(organization_slug) if organization_slug else []
    user_map = {}
    for member in members:
        user = member.get('user')
        if user:
            user_id = user.get('id')
            username = user.get('username')
            user_map[user_id] = username
    
    logger.info(f"âœ… æ‰¾åˆ° {len(user_map)} ä¸ªæˆå‘˜")
    
    # 5. ç»Ÿè®¡æ¯ä¸ªä»»åŠ¡çš„è¿›åº¦
    logger.info(f"\nğŸ“Š åˆ†æä»»åŠ¡è¿›åº¦...")
    
    all_stats = []
    user_stats = defaultdict(lambda: {
        'total_jobs': 0,
        'new': 0,
        'in_progress': 0,
        'completed': 0,
        'validation': 0,
        'accepted': 0,
        'rejected': 0,
        'total_frames': 0,
        'completed_frames': 0,
        'total_duration': 0
    })
    
    for task in tasks:
        task_id = task['id']
        task_name = task['name']
        task_status = task.get('status')
        created_date = task.get('created_date', '')[:10]
        
        logger.info(f"\nå¤„ç†ä»»åŠ¡: {task_name} (ID: {task_id})")
        
        # è·å–ä»»åŠ¡çš„jobs
        jobs = client.get_task_jobs(task_id)
        
        if not jobs:
            logger.info(f"   â†’ æ²¡æœ‰jobs")
            continue
        
        logger.info(f"   â†’ Jobsæ•°: {len(jobs)}")
        logger.info(f"   â†’ æ£€æŸ¥æ ‡æ³¨çŠ¶æ€ï¼ˆå¹¶å‘ï¼‰...")
        
        # å¹¶å‘æ£€æŸ¥æ¯ä¸ªjobæ˜¯å¦æœ‰æ ‡æ³¨
        def check_job(job):
            job_id = job.get('id')
            has_annotations = client.get_job_has_annotations(job_id)
            return job_id, has_annotations
        
        job_annotations = {}
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = {executor.submit(check_job, job): job for job in jobs}
            completed = 0
            for future in as_completed(futures):
                job_id, has_annotations = future.result()
                job_annotations[job_id] = has_annotations
                completed += 1
                if completed % 10 == 0 or completed == len(jobs):
                    logger.info(f"      è¿›åº¦: {completed}/{len(jobs)} jobs")
        
        # ç»Ÿè®¡ä»»åŠ¡çº§åˆ«çš„ä¿¡æ¯
        task_stats = {
            'task_id': task_id,
            'task_name': task_name,
            'task_status': task_status,
            'created_date': created_date,
            'total_jobs': len(jobs),
            'job_stats': defaultdict(int),
            'assignee_stats': defaultdict(lambda: defaultdict(int)),
            'total_frames': 0,
            'completed_frames': 0
        }
        
        for job in jobs:
            job_id = job['id']
            state = job.get('state', 'new')
            assignee = job.get('assignee')
            start_frame = job.get('start_frame', 0)
            stop_frame = job.get('stop_frame', 0)
            frame_count = stop_frame - start_frame + 1
            
            # æ£€æŸ¥è¿™ä¸ªjobæ˜¯å¦æœ‰å®é™…æ ‡æ³¨
            has_annotations = job_annotations.get(job_id, False)
            
            # ç»Ÿè®¡jobçŠ¶æ€
            task_stats['job_stats'][state] += 1
            task_stats['total_frames'] += frame_count
            
            # å¦‚æœæœ‰å®é™…æ ‡æ³¨æ•°æ®ï¼Œè®¡å…¥å®Œæˆå¸§æ•°
            if has_annotations:
                task_stats['completed_frames'] += frame_count
            
            # ç»Ÿè®¡æ¯ä¸ªæ ‡æ³¨äººå‘˜çš„æƒ…å†µ
            if assignee:
                assignee_id = assignee.get('id')
                assignee_username = assignee.get('username')
                assignee_name = user_map.get(assignee_id, assignee_username or f"User_{assignee_id}")
                
                task_stats['assignee_stats'][assignee_name]['total'] += 1
                task_stats['assignee_stats'][assignee_name][state] += 1
                task_stats['assignee_stats'][assignee_name]['frames'] += frame_count
                
                # å…¨å±€ç»Ÿè®¡
                user_stats[assignee_name]['total_jobs'] += 1
                user_stats[assignee_name][state] += 1
                user_stats[assignee_name]['total_frames'] += frame_count
                
                # å¦‚æœæœ‰å®é™…æ ‡æ³¨æ•°æ®ï¼Œè®¡å…¥å®Œæˆ
                if has_annotations:
                    user_stats[assignee_name]['completed_frames'] += frame_count
                    task_stats['assignee_stats'][assignee_name]['has_annotations'] = \
                        task_stats['assignee_stats'][assignee_name].get('has_annotations', 0) + 1
        
        all_stats.append(task_stats)
    
    # 6. æ˜¾ç¤ºç»“æœ
    logger.info("\n" + "="*80)
    logger.info("ğŸ“Š ä»»åŠ¡è¿›åº¦æ±‡æ€»")
    logger.info("="*80)
    
    for task_stat in all_stats:
        logger.info(f"\nğŸ“Œ ä»»åŠ¡: {task_stat['task_name']} (ID: {task_stat['task_id']})")
        logger.info(f"   åˆ›å»ºæ—¥æœŸ: {task_stat['created_date']}")
        logger.info(f"   ä»»åŠ¡çŠ¶æ€: {task_stat['task_status']}")
        logger.info(f"   æ€»Jobsæ•°: {task_stat['total_jobs']}")
        logger.info(f"   æ€»å¸§æ•°: {task_stat['total_frames']}")
        logger.info(f"   å®Œæˆå¸§æ•°: {task_stat['completed_frames']} ({task_stat['completed_frames']*100//task_stat['total_frames'] if task_stat['total_frames'] > 0 else 0}%)")
        
        # JobçŠ¶æ€åˆ†å¸ƒ
        logger.info(f"\n   JobçŠ¶æ€åˆ†å¸ƒ:")
        for state, count in sorted(task_stat['job_stats'].items()):
            percentage = count * 100 // task_stat['total_jobs'] if task_stat['total_jobs'] > 0 else 0
            logger.info(f"     - {state}: {count} ({percentage}%)")
        
        # æ ‡æ³¨äººå‘˜ç»Ÿè®¡
        if task_stat['assignee_stats']:
            logger.info(f"\n   æ ‡æ³¨äººå‘˜è¿›åº¦:")
            for assignee, stats in sorted(task_stat['assignee_stats'].items()):
                total = stats['total']
                # ä½¿ç”¨å®é™…æ ‡æ³¨æ•°æ®åˆ¤æ–­å®Œæˆæƒ…å†µ
                has_annotations = stats.get('has_annotations', 0)
                in_progress = stats.get('in_progress', 0)
                new = stats.get('new', 0)
                frames = stats.get('frames', 0)
                
                completion_rate = has_annotations * 100 // total if total > 0 else 0
                
                logger.info(f"     ğŸ‘¤ {assignee}:")
                logger.info(f"        æ€»ä»»åŠ¡: {total} | å®é™…å®Œæˆ: {has_annotations} ({completion_rate}%)")
                logger.info(f"        è¿›è¡Œä¸­: {in_progress} | æœªå¼€å§‹: {new}")
                logger.info(f"        æ€»å¸§æ•°: {frames}")
    
    # 7. å…¨å±€æ ‡æ³¨äººå‘˜ç»Ÿè®¡
    logger.info("\n" + "="*80)
    logger.info("ğŸ‘¥ æ ‡æ³¨äººå‘˜æ€»ä½“è¿›åº¦")
    logger.info("="*80)
    
    if user_stats:
        # æŒ‰å®Œæˆç‡æ’åº
        sorted_users = sorted(
            user_stats.items(),
            key=lambda x: (x[1]['completed'] + x[1]['accepted']) / x[1]['total_jobs'] if x[1]['total_jobs'] > 0 else 0,
            reverse=True
        )
        
        for assignee, stats in sorted_users:
            total = stats['total_jobs']
            # ç”¨å®é™…æ ‡æ³¨åˆ¤æ–­å®Œæˆ
            completed = stats.get('completed_frames', 0) // (stats['total_frames'] // stats['total_jobs']) if stats['total_frames'] > 0 else 0
            # ç®€åŒ–ï¼šæœ‰completed_frameså°±ç®—å®Œæˆçš„jobs
            actual_completed_jobs = sum(1 for _ in range(stats['total_jobs']) if stats.get('completed_frames', 0) > 0)
            
            in_progress = stats['in_progress']
            new = stats['new']
            total_frames = stats['total_frames']
            completed_frames = stats['completed_frames']
            
            completion_rate = completed_frames * 100 // total_frames if total_frames > 0 else 0
            
            logger.info(f"\nğŸ‘¤ {assignee}:")
            logger.info(f"   æ€»ä»»åŠ¡: {total}")
            logger.info(f"   å·²å®Œæˆå¸§æ•°: {completed_frames}/{total_frames} ({completion_rate}%)")
            logger.info(f"   è¿›è¡Œä¸­: {in_progress} | æœªå¼€å§‹: {new}")
            
            # è¿›åº¦æ¡
            bar_length = 40
            filled = int(bar_length * completion_rate / 100)
            bar = 'â–ˆ' * filled + 'â–‘' * (bar_length - filled)
            logger.info(f"   è¿›åº¦: [{bar}] {completion_rate}%")
    else:
        sorted_users = []
        logger.info("   æœªæ‰¾åˆ°å·²åˆ†é…çš„ä»»åŠ¡")
    
    # 8. ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    report_file = log_dir / f'progress_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
    
    report = {
        'generated_at': datetime.now().isoformat(),
        'summary': {
            'total_tasks': len(all_stats),
            'total_users': len(user_stats)
        },
        'tasks': all_stats,
        'users': dict(user_stats)
    }
    
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False, default=str)
    
    logger.info(f"\nâœ… è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    logger.info(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {log_file}")
    
    # 9. ç”Ÿæˆç®€å•çš„æ¯æ—¥æŠ¥å‘Š
    daily_report_file = log_dir / f'daily_report_{datetime.now().strftime("%Y%m%d")}.txt'
    
    with open(daily_report_file, 'w', encoding='utf-8') as f:
        f.write(f"æ ‡æ³¨è¿›åº¦æ—¥æŠ¥ - {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}\n")
        f.write("="*60 + "\n\n")
        
        f.write("ğŸ“Š æ€»ä½“æƒ…å†µ\n")
        f.write(f"  ä»»åŠ¡æ•°: {len(all_stats)}\n")
        f.write(f"  æ ‡æ³¨äººå‘˜: {len(user_stats)}\n\n")
        
        f.write("ğŸ‘¥ æ ‡æ³¨äººå‘˜è¿›åº¦\n")
        f.write("-"*60 + "\n")
        
        for assignee, stats in sorted_users:
            total = stats['total_jobs']
            total_frames = stats['total_frames']
            completed_frames = stats.get('completed_frames', 0)
            
            completion_rate = completed_frames * 100 // total_frames if total_frames > 0 else 0
            
            f.write(f"\n{assignee}:\n")
            f.write(f"  æ€»ä»»åŠ¡: {total}\n")
            f.write(f"  å®Œæˆå¸§æ•°: {completed_frames}/{total_frames} ({completion_rate}%)\n")
        
        f.write("\n" + "="*60 + "\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    logger.info(f"ğŸ“„ æ¯æ—¥æŠ¥å‘Šå·²ä¿å­˜: {daily_report_file}")
    
    logger.info("\n" + "="*80)


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    import sys
    
    task_ids = None
    if len(sys.argv) > 1:
        # æ”¯æŒæŒ‡å®šä»»åŠ¡ID
        try:
            task_ids = [int(tid) for tid in sys.argv[1:]]
            logger.info(f"æ£€æŸ¥æŒ‡å®šä»»åŠ¡: {task_ids}")
        except ValueError:
            logger.error("âŒ ä»»åŠ¡IDå¿…é¡»æ˜¯æ•°å­—")
            logger.info("ç”¨æ³•: python check_progress.py [task_id1] [task_id2] ...")
            return
    
    check_progress(task_ids=task_ids)


if __name__ == "__main__":
    main()
