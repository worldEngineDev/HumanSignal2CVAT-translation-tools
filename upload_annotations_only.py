#!/usr/bin/env python3
"""
å•ç‹¬ä¸Šä¼ æ ‡æ³¨åˆ°å·²å­˜åœ¨çš„CVATä»»åŠ¡
"""
import requests
import json
import zipfile
import io
import logging
from pathlib import Path
from datetime import datetime

# é…ç½®æ—¥å¿—
log_dir = Path('logs')
log_dir.mkdir(exist_ok=True)
log_file = log_dir / f'upload_annotations_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler(log_file, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


def upload_annotations(cvat_url, api_key, task_id, annotation_data):
    """ä¸Šä¼ æ ‡æ³¨åˆ°æŒ‡å®šä»»åŠ¡"""
    url = f'{cvat_url}/api/tasks/{task_id}/annotations'
    params = {'format': 'COCO 1.0'}
    
    # åˆ›å»ºå†…å­˜ä¸­çš„zipæ–‡ä»¶
    zip_buffer = io.BytesIO()
    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zipf:
        json_str = json.dumps(annotation_data, ensure_ascii=False, indent=2)
        zipf.writestr('annotations/instances_default.json', json_str)
    
    zip_buffer.seek(0)
    
    headers = {'Authorization': f'Token {api_key}'}
    files = {'annotation_file': ('annotations.zip', zip_buffer, 'application/zip')}
    
    try:
        response = requests.post(
            url, 
            headers=headers, 
            params=params, 
            files=files,
            timeout=120
        )
        response.raise_for_status()
        logger.info(f"âœ… æ ‡æ³¨ä¸Šä¼ æˆåŠŸ: task_id={task_id}")
        return True
    except requests.exceptions.RequestException as e:
        logger.error(f"âŒ ä¸Šä¼ æ ‡æ³¨å¤±è´¥: {e}")
        if hasattr(e, 'response') and e.response is not None:
            logger.error(f"   å“åº”å†…å®¹: {e.response.text}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    logger.info("="*60)
    logger.info("å•ç‹¬ä¸Šä¼ æ ‡æ³¨åˆ°CVATä»»åŠ¡")
    logger.info("="*60)
    
    # 1. åŠ è½½é…ç½®
    logger.info("ğŸ“– åŠ è½½é…ç½®...")
    with open('config.json', 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    cvat_url = config['cvat']['url'].rstrip('/')
    api_key = config['cvat']['api_key']
    input_json = config['files']['humansignal_json']
    
    # 2. è¾“å…¥ä»»åŠ¡ID
    task_id = input("è¯·è¾“å…¥ä»»åŠ¡ID: ").strip()
    if not task_id:
        logger.error("âŒ ä»»åŠ¡IDä¸èƒ½ä¸ºç©º")
        return
    
    logger.info(f"ç›®æ ‡ä»»åŠ¡: {task_id}")
    
    # 3. è¯»å–æ ‡æ³¨æ•°æ®
    logger.info(f"ğŸ“– è¯»å–æ ‡æ³¨æ•°æ®: {input_json}")
    with open(input_json, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    logger.info(f"   æ€»å›¾ç‰‡æ•°: {len(data['images'])}")
    logger.info(f"   æ€»æ ‡æ³¨æ•°: {len(data['annotations'])}")
    logger.info(f"   ç±»åˆ«æ•°: {len(data['categories'])}")
    
    # 4. è½¬æ¢å›¾ç‰‡è·¯å¾„
    logger.info("ğŸ”„ è½¬æ¢å›¾ç‰‡è·¯å¾„...")
    converted_images = []
    
    for img in data['images']:
        original_path = img['file_name']
        
        # è½¬æ¢è·¯å¾„
        basename = original_path.split('/')[-1]
        if '__' in basename:
            basename = basename.split('__', 1)[1]
        
        # æ·»åŠ  prefix å‰ç¼€
        new_path = f"test_1000/images/{basename}"
        
        # åˆ›å»ºæ–°çš„imageå¯¹è±¡
        new_img = img.copy()
        new_img['file_name'] = new_path
        converted_images.append(new_img)
    
    logger.info(f"   å·²è½¬æ¢ {len(converted_images)} ä¸ªå›¾ç‰‡è·¯å¾„")
    
    # 5. ç¡®ä¿ categories æ ¼å¼æ­£ç¡®ï¼ˆCVAT éœ€è¦ category_id ä» 1 å¼€å§‹ï¼‰
    logger.info("ğŸ·ï¸  å¤„ç†ç±»åˆ«ä¿¡æ¯...")
    # æŒ‰ category ID æ’åºï¼Œç¡®ä¿é¡ºåºä¸€è‡´
    categories_sorted = sorted(data['categories'], key=lambda x: x['id'])
    converted_categories = []
    category_id_mapping = {}  # æ—§ID -> æ–°ID
    
    for idx, cat in enumerate(categories_sorted):
        new_id = idx + 1  # ä» 1 å¼€å§‹
        category_id_mapping[cat['id']] = new_id
        converted_cat = {
            'id': new_id,
            'name': cat['name'],
            'supercategory': cat.get('supercategory', '')
        }
        converted_categories.append(converted_cat)
    
    logger.info(f"   ç±»åˆ«åˆ—è¡¨: {[cat['name'] for cat in converted_categories]}")
    logger.info(f"   ç±»åˆ«IDæ˜ å°„: {category_id_mapping}")
    
    # è½¬æ¢æ ‡æ³¨ä¸­çš„ category_id
    converted_annotations = []
    for ann in data['annotations']:
        new_ann = ann.copy()
        old_cat_id = ann['category_id']
        new_ann['category_id'] = category_id_mapping.get(old_cat_id, old_cat_id + 1)
        converted_annotations.append(new_ann)
    
    # 6. æ„å»ºæœ€ç»ˆæ•°æ®
    converted_data = {
        'images': converted_images,
        'annotations': converted_annotations,
        'categories': converted_categories
    }
    
    logger.info(f"\nğŸ“Š å‡†å¤‡ä¸Šä¼ :")
    logger.info(f"   å›¾ç‰‡: {len(converted_images)}")
    logger.info(f"   æ ‡æ³¨: {len(converted_annotations)}")
    logger.info(f"   ç±»åˆ«: {len(converted_categories)}")
    
    # 7. ç¡®è®¤ä¸Šä¼ 
    confirm = input("\nç¡®è®¤ä¸Šä¼ ï¼Ÿ(yes/no): ").strip().lower()
    if confirm != 'yes':
        logger.info("âŒ å–æ¶ˆä¸Šä¼ ")
        return
    
    # 8. ä¸Šä¼ æ ‡æ³¨
    logger.info("\nğŸ“¤ å¼€å§‹ä¸Šä¼ æ ‡æ³¨...")
    success = upload_annotations(cvat_url, api_key, task_id, converted_data)
    
    if success:
        logger.info("\n" + "="*60)
        logger.info("âœ… ä¸Šä¼ å®Œæˆï¼")
        logger.info("="*60)
        logger.info(f"ğŸ”— æŸ¥çœ‹ä»»åŠ¡: {cvat_url}/tasks/{task_id}")
        logger.info(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {log_file}")
    else:
        logger.error("\nâŒ ä¸Šä¼ å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—")


if __name__ == "__main__":
    main()
